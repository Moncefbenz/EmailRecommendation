{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import email, glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from flanker import mime\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_content_in_braces(msg) :\n",
    "\tmsg1 = ''\n",
    "\tcnt = 0\n",
    "\tfor char in msg :\n",
    "\t\tif char == '{' :\n",
    "\t\t\tcnt += 1\n",
    "\t\telif char == '}' :\n",
    "\t\t\tcnt -= 1\n",
    "\t\telif cnt == 0 :\n",
    "\t\t\tmsg1 += char\n",
    "\t\telse :\n",
    "\t\t\tcontinue\n",
    "\treturn msg1\n",
    "\n",
    "def remove_func_and_struct(msg) :\n",
    "\tmsg1 = ''\n",
    "\ttake_line = True\n",
    "\tmsg = msg.splitlines()\n",
    "\tfor line in msg :\n",
    "\t\ttake_line = True\n",
    "\t\tif line == '' :\n",
    "\t\t\tcontinue\n",
    "\t\twords = line.split(' ')\n",
    "\t\tif words[0] == \"func\" :\n",
    "\t\t\ttake_line = False\n",
    "\t\telif words[0] == \"type\" :\n",
    "\t\t\tif len(words)  >= 3  and words[2] == \"struct\" :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\tif take_line :\n",
    "\t\t\tmsg1 += (line + '\\n')\n",
    "\treturn msg1\n",
    "\n",
    "def remove_other_code_lines(msg) :\n",
    "\tmsg1 = ''\n",
    "\ttake_line = True\n",
    "\tmsg = msg.splitlines()\n",
    "\ti = 0\t\n",
    "\twhile i < len(msg) :\n",
    "\t\tif (msg[i] == '') or (\"//\" in msg[i]) :\n",
    "\t\t\ti += 1\n",
    "\t\t\tcontinue\n",
    "\t\ttake_line = True\n",
    "\t\tline = msg[i]\n",
    "\t\tif \"package\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\telif \"import\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\t\t\tif \"(\" in line :\n",
    "\t\t\t\t\twhile ')' not in msg[i] :\n",
    "\t\t\t\t\t\ti += 1\n",
    "\t\telif \"const\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\t\t\tif \"(\" in line :\n",
    "\t\t\t\t\twhile ')' not in msg[i] :\n",
    "\t\t\t\t\t\ti += 1\n",
    "\t\tif take_line :\n",
    "\t\t\tmsg1 += line + '\\n'\n",
    "\t\ti += 1\n",
    "\treturn msg1\n",
    "\n",
    "\n",
    "def remove_code(msg) :\n",
    "\tmsg = (remove_content_in_braces(msg))\n",
    "\tmsg = (remove_func_and_struct(msg))\n",
    "\tmsg = (remove_other_code_lines(msg))\n",
    "\treturn msg\n",
    "\n",
    "def get_header(msg):\n",
    "    msg = email.message_from_string(msg)\n",
    "    mfrom = msg['From'].split('<')[0]\n",
    "    return mfrom\n",
    "    \n",
    "def flan(msg):\n",
    "    rt = ''\n",
    "    msg = mime.from_string(msg)\n",
    "    if msg.content_type.is_singlepart():\n",
    "      temp = str(msg.body)\n",
    "      temp = temp.splitlines()\n",
    "      for _ in temp:\n",
    "          if _.startswith('>'):\n",
    "              continue\n",
    "          elif _.startswith('On'):\n",
    "              continue\n",
    "          else:\n",
    "              rt+=_+\"\\n\"\n",
    "    else :\n",
    "      for part in msg.parts :\n",
    "          if \"(text/plain)\" in str(part) :\n",
    "              temp = str(part.body)\n",
    "              temp = temp.splitlines()\n",
    "              for _ in temp :\n",
    "                  if _.startswith('>') :\n",
    "                      continue\n",
    "                  if _.startswith('On'):\n",
    "                      continue\n",
    "                  else :\n",
    "                      rt+=_+\"\\n\"\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt =''\n",
    "fpath = \"/home/anuja/Desktop/BE project/Models/EmailRecommmendation/features/Dataset/*/*.email\"\n",
    "files = glob.glob(fpath)\n",
    "for file in files :\n",
    "  f = open(file, \"r\")\n",
    "  msg = f.read()\n",
    "  msg = mime.from_string(msg)\n",
    "  if msg.content_type.is_singlepart():\n",
    "      temp = str(msg.body)\n",
    "      temp = temp.splitlines()\n",
    "      for _ in temp:\n",
    "          if _.startswith('>'):\n",
    "              continue\n",
    "          elif _.startswith('On'):\n",
    "              continue\n",
    "          else:\n",
    "              rt+=_+\"\\n\"\n",
    "  else :\n",
    "      for part in msg.parts :\n",
    "          if \"(text/plain)\" in str(part) :\n",
    "              temp = str(part.body)\n",
    "              temp = temp.splitlines()\n",
    "              for _ in temp :\n",
    "                  if _.startswith('>') :\n",
    "                      continue\n",
    "                  if _.startswith('On'):\n",
    "                      continue\n",
    "                  else :\n",
    "                      rt+=_+\"\\n\"\n",
    "               \n",
    "rt = remove_code(rt)\n",
    "# print(rt)\n",
    "rt = rt.split('\\n')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(rt)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "max_words=total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['body','replier', 'thread_no'])\n",
    "users = []\n",
    "fpath = \"/home/anuja/Desktop/BE project/Models/EmailRecommmendation/features/Dataset/*\"\n",
    "folder = glob.glob(fpath)\n",
    "th_no = 0\n",
    "\n",
    "for fol in folder:\n",
    "    files = glob.glob(fol+'/*.email')\n",
    "    flag = 0\n",
    "    t = ''\n",
    "    for file in files:\n",
    "        if flag==0:\n",
    "            data = open(file,'r')\n",
    "            temp = data.read()\n",
    "            header = get_header(temp)\n",
    "            temp = flan(temp)\n",
    "            temp = remove_code(temp)\n",
    "            t = temp\n",
    "            flag = 1\n",
    "            users.append(header)\n",
    "            \n",
    "            continue\n",
    "        data = open(file,'r')\n",
    "        temp = data.read()\n",
    "        header = get_header(temp)\n",
    "        users.append(header)\n",
    "        temp = flan(temp)\n",
    "        temp = remove_code(temp)\n",
    "        df = df.append({'body': t,'replier':header, 'thread_no':th_no}, ignore_index=True)\n",
    "        t = t + temp\n",
    "    th_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of                                                  body  \\\n",
      "0   The make file for contributing code is:\\ninclu...   \n",
      "1   The make file for contributing code is:\\ninclu...   \n",
      "2   The make file for contributing code is:\\ninclu...   \n",
      "3   The make file for contributing code is:\\ninclu...   \n",
      "4   The make file for contributing code is:\\ninclu...   \n",
      "5   ray <r...@hollett.demon.co.uk> writes:\\nFrom y...   \n",
      "6   ray <r...@hollett.demon.co.uk> writes:\\nFrom y...   \n",
      "7   2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "8   2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "9   2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "10  2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "11  2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "12  2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "13  2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "14  2009/12/3 Rick R <rick.ri...@gmail.com>\\nIt's ...   \n",
      "15  ziyu_huang <ziyu4...@gmail.com> writes:\\nThere...   \n",
      "16  ziyu_huang <ziyu4...@gmail.com> writes:\\nThere...   \n",
      "17  ziyu_huang <ziyu4...@gmail.com> writes:\\nThere...   \n",
      "18  ziyu_huang <ziyu4...@gmail.com> writes:\\nThere...   \n",
      "19  Just stumbled across this in Slashdot:\\nWhich ...   \n",
      "20  Just stumbled across this in Slashdot:\\nWhich ...   \n",
      "21  Just stumbled across this in Slashdot:\\nWhich ...   \n",
      "22  Just stumbled across this in Slashdot:\\nWhich ...   \n",
      "23  Be \"go language\" going to support  android ui ...   \n",
      "24  Consider this:\\nmain\\nv1 test\\nv1 test\\nmalkia...   \n",
      "25  Consider this:\\nmain\\nv1 test\\nv1 test\\nmalkia...   \n",
      "26  Consider this:\\nmain\\nv1 test\\nv1 test\\nmalkia...   \n",
      "27  Consider this:\\nmain\\nv1 test\\nv1 test\\nmalkia...   \n",
      "28  Consider this:\\nmain\\nv1 test\\nv1 test\\nmalkia...   \n",
      "29  wouldn't import (\"/a/b/c\"; \"/a/b/e\") work for ...   \n",
      "..                                                ...   \n",
      "38  Got it, thanks!!!\\nHi,\\nI trid to use ajax to ...   \n",
      "39  Got it, thanks!!!\\nHi,\\nI trid to use ajax to ...   \n",
      "40  Got it, thanks!!!\\nHi,\\nI trid to use ajax to ...   \n",
      "41  Got it, thanks!!!\\nHi,\\nI trid to use ajax to ...   \n",
      "42  I'm looking at the math package and I'm not se...   \n",
      "43  I'm looking at the math package and I'm not se...   \n",
      "44  Hi Russ,\\nThanks for your reply. I am not root...   \n",
      "45  Hi Russ,\\nThanks for your reply. I am not root...   \n",
      "46  Hi Russ,\\nThanks for your reply. I am not root...   \n",
      "47  Hi Russ,\\nThanks for your reply. I am not root...   \n",
      "48  Hi Russ,\\nThanks for your reply. I am not root...   \n",
      "49  I'm trying to write a simple web server but i ...   \n",
      "50  I'm trying to write a simple web server but i ...   \n",
      "51  \"there are lots of those things like that you ...   \n",
      "52  Why do you need default implements if you can'...   \n",
      "53  Why do you need default implements if you can'...   \n",
      "54  Why do you need default implements if you can'...   \n",
      "55  Why do you need default implements if you can'...   \n",
      "56  Why do you need default implements if you can'...   \n",
      "57  Why do you need default implements if you can'...   \n",
      "58  Why do you need default implements if you can'...   \n",
      "59  Why do you need default implements if you can'...   \n",
      "60  Why do you need default implements if you can'...   \n",
      "61  First work on release.  Then work on head.  Th...   \n",
      "62  First work on release.  Then work on head.  Th...   \n",
      "63  First work on release.  Then work on head.  Th...   \n",
      "64  First work on release.  Then work on head.  Th...   \n",
      "65  First work on release.  Then work on head.  Th...   \n",
      "66  First work on release.  Then work on head.  Th...   \n",
      "67  First work on release.  Then work on head.  Th...   \n",
      "\n",
      "                         replier thread_no  \n",
      "0                  Daniel Dilts          0  \n",
      "1               Myron Alexander          0  \n",
      "2                      Russ Cox          0  \n",
      "3              Ian Lance Taylor          0  \n",
      "4                  Daniel Dilts          0  \n",
      "5                      emghazal          1  \n",
      "6                           ray          1  \n",
      "7                        Rick R          2  \n",
      "8                        Rick R          2  \n",
      "9                      OwlHuntr          2  \n",
      "10              Rick Richardson          2  \n",
      "11                       Rick R          2  \n",
      "12                       Rick R          2  \n",
      "13                       atomly          2  \n",
      "14                       Jessta          2  \n",
      "15                     Russ Cox          3  \n",
      "16                   ziyu_huang          3  \n",
      "17                 baldmountain          3  \n",
      "18                Esko Luontola          3  \n",
      "19               Bob Cunningham          4  \n",
      "20                  Pete Wilson          4  \n",
      "21               Joseph Stewart          4  \n",
      "22                  Pete Wilson          4  \n",
      "23                 Rowan Davies          5  \n",
      "24  \"Dimiter \\\"malkia\\\" Stanev\"          6  \n",
      "25             Ian Lance Taylor          6  \n",
      "26  \"Dimiter \\\"malkia\\\" Stanev\"          6  \n",
      "27                   ziyu_huang          6  \n",
      "28                     Russ Cox          6  \n",
      "29            gorgo...@online.de         7  \n",
      "..                           ...       ...  \n",
      "38                  Ben Bullock         10  \n",
      "39                       Mad Go         10  \n",
      "40                  Ben Bullock         10  \n",
      "41                       Mad Go         10  \n",
      "42                 Isaac Wagner         11  \n",
      "43                     OwlHuntr         11  \n",
      "44                     Russ Cox         12  \n",
      "45                   ziyu_huang         12  \n",
      "46                   ziyu_huang         12  \n",
      "47                     Russ Cox         12  \n",
      "48                 Adam Langley         12  \n",
      "49                     OwlHuntr         13  \n",
      "50            Frederik Deweerdt         13  \n",
      "51            gorgo...@online.de        14  \n",
      "52                 Daniel Dilts         15  \n",
      "53                 Daniel Dilts         15  \n",
      "54                       Helmar         15  \n",
      "55                        SnakE         15  \n",
      "56                    Evan Shaw         15  \n",
      "57               Duncan Pearson         15  \n",
      "58                 Daniel Dilts         15  \n",
      "59                    i3dmaster         15  \n",
      "60                       Helmar         15  \n",
      "61                     Russ Cox         16  \n",
      "62            Geoffrey Clements         16  \n",
      "63            \"Devon H. O'Dell\"         16  \n",
      "64                 baldmountain         16  \n",
      "65            \"Devon H. O'Dell\"         16  \n",
      "66            Frederik Deweerdt         16  \n",
      "67            Geoffrey Clements         16  \n",
      "\n",
      "[68 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "[0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 9, 10, 10, 10, 10, 10, 11, 11, 12, 12, 12, 12, 12, 13, 13, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16]\n"
     ]
    }
   ],
   "source": [
    "h = df.replier\n",
    "pprint(len(h))\n",
    "h=list(h)\n",
    "\n",
    "thread_no_list = df.thread_no\n",
    "thread_no_list = list(thread_no_list)\n",
    "print(thread_no_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6 19 25 13  6 13 30 36 26 22 22 20 23 22 22 28 16 13 25 37 29  8  5\n",
      "  5 21 17 21  2 24  1  1 13  1 37 25 33 31 33  1 33 26 37  6 35 15 25 18\n",
      " 18  4 18  4 18 14 14 20 37 25 37 37 25  3 27 20 10 34 31 37  6  6 12 26\n",
      "  9  7  6 33 12 24 25 11  0 29  0 10 11 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold = sys.maxsize)\n",
    "val = np.array(users)\n",
    "w = open('one_hot.txt','w')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(val)\n",
    "print(integer_encoded)\n",
    "user_indices = integer_encoded\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "output_shape = one_hot_encoded.shape[1]\n",
    "w.write(str(one_hot_encoded))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6 19 25 13  6 13 30 36 26 22 22 20 23 22 22 28 16 13 25 37 29  8  5\n",
      "  5 21 17 21  2 24  1  1 13  1 37 25 33 31 33  1 33 26 37  6 35 15 25 18\n",
      " 18  4 18  4 18 14 14 20 37 25 37 37 25  3 27 20 10 34 31 37  6  6 12 26\n",
      "  9  7  6 33 12 24 25 11  0 29  0 10 11 32]\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(user_indices)\n",
    "input_weights = []\n",
    "user_size = max(user_indices) + 1\n",
    "print(user_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_encoded_final = []\n",
    "for replier in h:\n",
    "    idx1 = label_encoder.transform([replier])\n",
    "    onehot = np.zeros(user_size)\n",
    "    onehot[idx1] = 1\n",
    "    onehot_encoded_final.append(list(onehot))\n",
    "one_hot_encoded_final = np.array(onehot_encoded_final)\n",
    "print(type(one_hot_encoded_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 38)\n"
     ]
    }
   ],
   "source": [
    "#Binary encoding of users participating in each thread\n",
    "\n",
    "index=0\n",
    "weight_list = []\n",
    "for i in range(0, max(thread_no_list)+1):\n",
    "#     temp = np.zeros(user_size)\n",
    "    temp_index=index\n",
    "#     print(temp)\n",
    "    array  = np.zeros(user_size)\n",
    "    for j in range(temp_index, temp_index + thread_no_list.count(i)):\n",
    "#         print(user_indices[j], end = \",\")\n",
    "        array[user_indices[j]] += 1\n",
    "        weight_list.append(list(array))\n",
    "#         temp[user_indices[j]] += 1\n",
    "        index+=1\n",
    "#     print(\"\\n\")\n",
    "#     print(temp,\"\\n\")\n",
    "\n",
    "weights = np.array(weight_list)\n",
    "pprint(weights.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.body\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest(l):\n",
    "    m=0\n",
    "    for k in l:\n",
    "        m = max(len(k),m)\n",
    "    return m\n",
    "max_len = longest(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "# max_words = 1294\n",
    "# max_len = 3267\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(x_train)\n",
    "sequences = tok.texts_to_sequences(x_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "print(type(sequences_matrix))\n",
    "print(len(sequences_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.zeros(user_size)\n",
    "a=tf.convert_to_tensor(b)\n",
    "#dense_cat = Dense(256, activation='relu')(a)\n",
    "#flat1 = Dense(32, activation='relu')(dense_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    inputs2 = Input(name='inputs2',shape=[user_size])\n",
    "    layer2=Dense(256,name='FC2')(inputs2)\n",
    "    \n",
    "    merge=concatenate([layer,layer2])\n",
    "    \n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(output_shape,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=[inputs,inputs2],outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 3182)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 3182, 50)          64700     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 38)                9766      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 38)                0         \n",
      "=================================================================\n",
      "Total params: 120,546\n",
      "Trainable params: 120,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 7s 124ms/step - loss: 0.6931 - acc: 0.5015 - val_loss: 0.6880 - val_acc: 0.9605\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.6876 - acc: 0.8796 - val_loss: 0.6802 - val_acc: 0.9737\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.6795 - acc: 0.9196 - val_loss: 0.6648 - val_acc: 0.9737\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 5s 84ms/step - loss: 0.6613 - acc: 0.9440 - val_loss: 0.6212 - val_acc: 0.9737\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 5s 98ms/step - loss: 0.6104 - acc: 0.9527 - val_loss: 0.3650 - val_acc: 0.9737\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.3676 - acc: 0.9605 - val_loss: 0.1845 - val_acc: 0.9737\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 6s 107ms/step - loss: 0.2003 - acc: 0.9688 - val_loss: 0.1481 - val_acc: 0.9737\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 0.1625 - acc: 0.9712 - val_loss: 0.1353 - val_acc: 0.9737\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 5s 92ms/step - loss: 0.1455 - acc: 0.9722 - val_loss: 0.1317 - val_acc: 0.9737\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.1410 - acc: 0.9732 - val_loss: 0.1309 - val_acc: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40805520b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([sequences_matrix,weights],one_hot_encoded_final,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
