{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import email, glob\n",
    "import pandas as pd\n",
    "from flanker import mime\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_content_in_braces(msg) :\n",
    "\tmsg1 = ''\n",
    "\tcnt = 0\n",
    "\tfor char in msg :\n",
    "\t\tif char == '{' :\n",
    "\t\t\tcnt += 1\n",
    "\t\telif char == '}' :\n",
    "\t\t\tcnt -= 1\n",
    "\t\telif cnt == 0 :\n",
    "\t\t\tmsg1 += char\n",
    "\t\telse :\n",
    "\t\t\tcontinue\n",
    "\treturn msg1\n",
    "\n",
    "def remove_func_and_struct(msg) :\n",
    "\tmsg1 = ''\n",
    "\ttake_line = True\n",
    "\tmsg = msg.splitlines()\n",
    "\tfor line in msg :\n",
    "\t\ttake_line = True\n",
    "\t\tif line == '' :\n",
    "\t\t\tcontinue\n",
    "\t\twords = line.split(' ')\n",
    "\t\tif words[0] == \"func\" :\n",
    "\t\t\ttake_line = False\n",
    "\t\telif words[0] == \"type\" :\n",
    "\t\t\tif len(words)  >= 3  and words[2] == \"struct\" :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\tif take_line :\n",
    "\t\t\tmsg1 += (line + '\\n')\n",
    "\treturn msg1\n",
    "\n",
    "def remove_other_code_lines(msg) :\n",
    "\tmsg1 = ''\n",
    "\ttake_line = True\n",
    "\tmsg = msg.splitlines()\n",
    "\ti = 0\t\n",
    "\twhile i < len(msg) :\n",
    "\t\tif (msg[i] == '') or (\"//\" in msg[i]) :\n",
    "\t\t\ti += 1\n",
    "\t\t\tcontinue\n",
    "\t\ttake_line = True\n",
    "\t\tline = msg[i]\n",
    "\t\tif \"package\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\telif \"import\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\t\t\tif \"(\" in line :\n",
    "\t\t\t\t\twhile ')' not in msg[i] :\n",
    "\t\t\t\t\t\ti += 1\n",
    "\t\telif \"const\" in line :\n",
    "\t\t\twords = line.split(' ')\n",
    "\t\t\tif len(words) < 4 :\n",
    "\t\t\t\ttake_line = False\n",
    "\t\t\t\tif \"(\" in line :\n",
    "\t\t\t\t\twhile ')' not in msg[i] :\n",
    "\t\t\t\t\t\ti += 1\n",
    "\t\tif take_line :\n",
    "\t\t\tmsg1 += line + '\\n'\n",
    "\t\ti += 1\n",
    "\treturn msg1\n",
    "\n",
    "\n",
    "def remove_code(msg) :\n",
    "\tmsg = (remove_content_in_braces(msg))\n",
    "\tmsg = (remove_func_and_struct(msg))\n",
    "\tmsg = (remove_other_code_lines(msg))\n",
    "\treturn msg\n",
    "\n",
    "def get_header(msg):\n",
    "    msg = email.message_from_string(msg)\n",
    "    mfrom = msg['From'].split('<')[0]\n",
    "    return mfrom\n",
    "    \n",
    "def flan(msg):\n",
    "    rt = ''\n",
    "    msg = mime.from_string(msg)\n",
    "    if msg.content_type.is_singlepart():\n",
    "      temp = str(msg.body)\n",
    "      temp = temp.splitlines()\n",
    "      for _ in temp:\n",
    "          if _.startswith('>'):\n",
    "              continue\n",
    "          elif _.startswith('On'):\n",
    "              continue\n",
    "          else:\n",
    "              rt+=_+\"\\n\"\n",
    "    else :\n",
    "      for part in msg.parts :\n",
    "          if \"(text/plain)\" in str(part) :\n",
    "              temp = str(part.body)\n",
    "              temp = temp.splitlines()\n",
    "              for _ in temp :\n",
    "                  if _.startswith('>') :\n",
    "                      continue\n",
    "                  if _.startswith('On'):\n",
    "                      continue\n",
    "                  else :\n",
    "                      rt+=_+\"\\n\"\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt =''\n",
    "fpath = \"/home/parth/BE_Project/EmailRecommmendation/features/Dataset/*/*.email\"\n",
    "files = glob.glob(fpath)\n",
    "for file in files :\n",
    "  f = open(file, \"r\")\n",
    "  msg = f.read()\n",
    "  msg = mime.from_string(msg)\n",
    "  if msg.content_type.is_singlepart():\n",
    "      temp = str(msg.body)\n",
    "      temp = temp.splitlines()\n",
    "      for _ in temp:\n",
    "          if _.startswith('>'):\n",
    "              continue\n",
    "          elif _.startswith('On'):\n",
    "              continue\n",
    "          else:\n",
    "              rt+=_+\"\\n\"\n",
    "  else :\n",
    "      for part in msg.parts :\n",
    "          if \"(text/plain)\" in str(part) :\n",
    "              temp = str(part.body)\n",
    "              temp = temp.splitlines()\n",
    "              for _ in temp :\n",
    "                  if _.startswith('>') :\n",
    "                      continue\n",
    "                  if _.startswith('On'):\n",
    "                      continue\n",
    "                  else :\n",
    "                      rt+=_+\"\\n\"\n",
    "               \n",
    "rt = remove_code(rt)\n",
    "# print(rt)\n",
    "rt = rt.split('\\n')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(rt)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "max_words=total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['body','replier', 'thread_no'])\n",
    "h = []\n",
    "fpath = \"/home/parth/BE_Project/EmailRecommmendation/features/Dataset/*\"\n",
    "folder = glob.glob(fpath)\n",
    "th_no = 0\n",
    "\n",
    "for fol in folder:\n",
    "    files = glob.glob(fol+'/*.email')\n",
    "    flag = 0\n",
    "    t = ''\n",
    "    for file in files:\n",
    "        if flag==0:\n",
    "            data = open(file,'r')\n",
    "            temp = data.read()\n",
    "            header = get_header(temp)\n",
    "            temp = flan(temp)\n",
    "            temp = remove_code(temp)\n",
    "            t = temp\n",
    "            flag = 1\n",
    "            h.append(header)\n",
    "            \n",
    "            continue\n",
    "        data = open(file,'r')\n",
    "        temp = data.read()\n",
    "        header = get_header(temp)\n",
    "        h.append(header)\n",
    "        temp = flan(temp)\n",
    "        temp = remove_code(temp)\n",
    "        df = df.append({'body': t,'replier':header, 'thread_no':th_no}, ignore_index=True)\n",
    "        t = t + temp\n",
    "    th_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                  body  \\\n",
      "0   Not at all. I was just trying to reduce the nu...   \n",
      "1   Not at all. I was just trying to reduce the nu...   \n",
      "2   Not at all. I was just trying to reduce the nu...   \n",
      "3   Not at all. I was just trying to reduce the nu...   \n",
      "4   Not at all. I was just trying to reduce the nu...   \n",
      "5   Not at all. I was just trying to reduce the nu...   \n",
      "6   Not at all. I was just trying to reduce the nu...   \n",
      "7   Not at all. I was just trying to reduce the nu...   \n",
      "8   A stupid question, but I use it quite often in...   \n",
      "9   A stupid question, but I use it quite often in...   \n",
      "10  A stupid question, but I use it quite often in...   \n",
      "11  A stupid question, but I use it quite often in...   \n",
      "12  Be \"go language\" going to support  android ui ...   \n",
      "13  Actually, there are more problems than those, ...   \n",
      "14  Actually, there are more problems than those, ...   \n",
      "15  Actually, there are more problems than those, ...   \n",
      "16  Actually, there are more problems than those, ...   \n",
      "17  I was a little surprised to find that string c...   \n",
      "18  I was a little surprised to find that string c...   \n",
      "19  If you have an older build of the code, you mi...   \n",
      "20  If you have an older build of the code, you mi...   \n",
      "21  If you have an older build of the code, you mi...   \n",
      "22  If you have an older build of the code, you mi...   \n",
      "23  If you have an older build of the code, you mi...   \n",
      "24                                Got it, thanks!!!\\n   \n",
      "25  Got it, thanks!!!\\nThis is the browser securit...   \n",
      "26  Got it, thanks!!!\\nThis is the browser securit...   \n",
      "27  Got it, thanks!!!\\nThis is the browser securit...   \n",
      "28  Got it, thanks!!!\\nThis is the browser securit...   \n",
      "29  I have client and server.\\n--- Client\\ntype\\tA...   \n",
      "..                                                ...   \n",
      "38  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "39  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "40  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "41  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "42  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "43  Daniel Dilts <dilts....@gmail.com> wrote:\\ngo ...   \n",
      "44                 yeaaaa... cot = tan^-1 = cos/sin\\n   \n",
      "45  yeaaaa... cot = tan^-1 = cos/sin\\nActually, co...   \n",
      "46  \"there are lots of those things like that you ...   \n",
      "47  I think Go's interface is a pure interface, it...   \n",
      "48  I think Go's interface is a pure interface, it...   \n",
      "49  I think Go's interface is a pure interface, it...   \n",
      "50  I think Go's interface is a pure interface, it...   \n",
      "51  I think Go's interface is a pure interface, it...   \n",
      "52  I think Go's interface is a pure interface, it...   \n",
      "53  I think Go's interface is a pure interface, it...   \n",
      "54  I think Go's interface is a pure interface, it...   \n",
      "55  I think Go's interface is a pure interface, it...   \n",
      "56  run make install\\nand then package b will be a...   \n",
      "57  run make install\\nand then package b will be a...   \n",
      "58  run make install\\nand then package b will be a...   \n",
      "59  run make install\\nand then package b will be a...   \n",
      "60  run make install\\nand then package b will be a...   \n",
      "61  once you get the whole request, you can then u...   \n",
      "62  once you get the whole request, you can then u...   \n",
      "63  My experience with aliasing packages... Am I d...   \n",
      "64  My experience with aliasing packages... Am I d...   \n",
      "65  My experience with aliasing packages... Am I d...   \n",
      "66  My experience with aliasing packages... Am I d...   \n",
      "67  My experience with aliasing packages... Am I d...   \n",
      "\n",
      "                         replier thread_no  \n",
      "0                         SnakE          0  \n",
      "1                        atomly          0  \n",
      "2               Rick Richardson          0  \n",
      "3                      OwlHuntr          0  \n",
      "4                        Rick R          0  \n",
      "5                        Jessta          0  \n",
      "6                        Rick R          0  \n",
      "7                        Rick R          0  \n",
      "8                      Russ Cox          1  \n",
      "9              Ian Lance Taylor          1  \n",
      "10                 baldmountain          1  \n",
      "11                Esko Luontola          1  \n",
      "12                 Rowan Davies          2  \n",
      "13               Bob Cunningham          3  \n",
      "14               Bob Cunningham          3  \n",
      "15               Joseph Stewart          3  \n",
      "16                  Pete Wilson          3  \n",
      "17                     emghazal          4  \n",
      "18             Ian Lance Taylor          4  \n",
      "19                     Russ Cox          5  \n",
      "20                   ziyu_huang          5  \n",
      "21                     Russ Cox          5  \n",
      "22                   ziyu_huang          5  \n",
      "23                   ziyu_huang          5  \n",
      "24                  Ben Bullock          6  \n",
      "25                       Mad Go          6  \n",
      "26                  Ben Bullock          6  \n",
      "27                       Mad Go          6  \n",
      "28                       Mad Go          6  \n",
      "29                     Russ Cox          7  \n",
      "..                           ...       ...  \n",
      "38  \"Dimiter \\\"malkia\\\" Stanev\"          9  \n",
      "39                 Daniel Dilts          9  \n",
      "40                   ziyu_huang          9  \n",
      "41                    i3dmaster          9  \n",
      "42                        SnakE          9  \n",
      "43                    i3dmaster          9  \n",
      "44                 Isaac Wagner         10  \n",
      "45                 Isaac Wagner         10  \n",
      "46            gorgo...@online.de        11  \n",
      "47                        SnakE         12  \n",
      "48               Duncan Pearson         12  \n",
      "49                    Evan Shaw         12  \n",
      "50                 Daniel Dilts         12  \n",
      "51                 Daniel Dilts         12  \n",
      "52                   ziyu_huang         12  \n",
      "53                       Helmar         12  \n",
      "54                       Helmar         12  \n",
      "55                 Daniel Dilts         12  \n",
      "56              Myron Alexander         13  \n",
      "57             Ian Lance Taylor         13  \n",
      "58                 Daniel Dilts         13  \n",
      "59                 Daniel Dilts         13  \n",
      "60                 Daniel Dilts         13  \n",
      "61            Frederik Deweerdt         14  \n",
      "62                     abiosoft         14  \n",
      "63             Ian Lance Taylor         15  \n",
      "64                   ziyu_huang         15  \n",
      "65  \"Dimiter \\\"malkia\\\" Stanev\"         15  \n",
      "66  \"Dimiter \\\"malkia\\\" Stanev\"         15  \n",
      "67                     Russ Cox         15  \n",
      "\n",
      "[68 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 15, 15, 15, 15, 15]\n"
     ]
    }
   ],
   "source": [
    "h = df.replier\n",
    "pprint(len(h))\n",
    "h=list(h)\n",
    "\n",
    "thread_no_list = df.thread_no\n",
    "thread_no_list = list(thread_no_list)\n",
    "print(thread_no_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 25 20 17 19 13 19 19 22 11 26  6 21  3  3 14 18 27 11 22 30 22 30 30\n",
      "  2 15  2 15 15 22  9 21  0 26  8  0  9 29  1  4 30 29 23 29 12 12 28 23\n",
      "  5  7  4  4 30 10 10  4 16 11  4  4  4  8 24 11 30  1  1 22]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold = sys.maxsize)\n",
    "val = np.array(h)\n",
    "w = open('one_hot.txt','w')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(val)\n",
    "\n",
    "user_indices = integer_encoded\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "output_shape = one_hot_encoded.shape[1]\n",
    "w.write(str(one_hot_encoded))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 25 20 17 19 13 19 19 22 11 26  6 21  3  3 14 18 27 11 22 30 22 30 30\n",
      "  2 15  2 15 15 22  9 21  0 26  8  0  9 29  1  4 30 29 23 29 12 12 28 23\n",
      "  5  7  4  4 30 10 10  4 16 11  4  4  4  8 24 11 30  1  1 22]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(user_indices)\n",
    "input_weights = []\n",
    "user_size = max(user_indices) + 1\n",
    "print(user_size)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23,25,20,17,19,13,19,19,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 3. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0.] \n",
      "\n",
      "22,11,26,6,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0.] \n",
      "\n",
      "21,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "3,3,14,18,\n",
      "\n",
      "[0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "27,11,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0.] \n",
      "\n",
      "22,30,22,30,30,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 3.] \n",
      "\n",
      "2,15,2,15,15,\n",
      "\n",
      "[0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "22,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "9,21,0,26,8,0,9,\n",
      "\n",
      "[2. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0.] \n",
      "\n",
      "29,1,4,30,29,23,29,\n",
      "\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 3. 1.] \n",
      "\n",
      "12,12,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "28,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0.] \n",
      "\n",
      "23,5,7,4,4,30,10,10,4,\n",
      "\n",
      "[0. 0. 0. 0. 3. 1. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1.] \n",
      "\n",
      "16,11,4,4,4,\n",
      "\n",
      "[0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "8,24,\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0.] \n",
      "\n",
      "11,30,1,1,22,\n",
      "\n",
      "[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Binary encoding of users participating in each thread\n",
    "\n",
    "index=0\n",
    "for i in range(0, max(thread_no_list)+1):\n",
    "    temp = np.zeros(user_size)\n",
    "    temp_index=index\n",
    "    #print(temp)\n",
    "    for j in range(temp_index, temp_index + thread_no_list.count(i)):\n",
    "        print(user_indices[j], end = \",\")\n",
    "        temp[user_indices[j]] += 1\n",
    "        index+=1\n",
    "    print(\"\\n\")\n",
    "    print(temp,\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.body\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest(l):\n",
    "    m=0\n",
    "    for k in l:\n",
    "        m = max(len(k),m)\n",
    "    return m\n",
    "max_len = longest(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words = 1294\n",
    "# max_len = 3267\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(x_train)\n",
    "sequences = tok.texts_to_sequences(x_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(output_shape,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 2843)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2843, 50)          63950     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 31)                7967      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 31)                0         \n",
      "=================================================================\n",
      "Total params: 117,997\n",
      "Trainable params: 117,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 14 samples\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.6933 - acc: 0.4851 - val_loss: 0.6881 - val_acc: 0.9562\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 0.6880 - acc: 0.8967 - val_loss: 0.6810 - val_acc: 0.9677\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.6807 - acc: 0.9373 - val_loss: 0.6685 - val_acc: 0.9677\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.6672 - acc: 0.9498 - val_loss: 0.6398 - val_acc: 0.9677\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 0.6377 - acc: 0.9492 - val_loss: 0.5238 - val_acc: 0.9677\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.5139 - acc: 0.9534 - val_loss: 0.2457 - val_acc: 0.9677\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.2531 - acc: 0.9636 - val_loss: 0.1749 - val_acc: 0.9677\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.1804 - acc: 0.9671 - val_loss: 0.1571 - val_acc: 0.9677\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.1655 - acc: 0.9671 - val_loss: 0.1515 - val_acc: 0.9677\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.1575 - acc: 0.9677 - val_loss: 0.1490 - val_acc: 0.9677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf345da780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,one_hot_encoded,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
