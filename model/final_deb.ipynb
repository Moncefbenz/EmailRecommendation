{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, building a Pandas dataframe and saving it as a  .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730bf66d5da14b569b90c2460e60ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import string\n",
    "from pprint import pprint\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = '/home/anuja/Documents/anu/EmailRecommmendation/'\n",
    "\n",
    "folder_path = \"/home/anuja/Desktop/mini_deb/*\"\n",
    "file_name = BASE_PATH + \"/model/dataframe3.csv\"\n",
    "file_name1 = BASE_PATH + \"/model/dataframe4.csv\"\n",
    "file_name2 = BASE_PATH + \"/model/dataframe5.csv\"\n",
    "sys.path.insert(0, BASE_PATH + '/Preprocessing')\n",
    "PATH = BASE_PATH + '/model/first_model.pt'\n",
    "\n",
    "import preprocessing\n",
    "import read_file\n",
    "import datetime\n",
    "\n",
    "def extract_debian(text):\n",
    "    text = text.split('\\n\\n\\n')\n",
    "    header = text[0].split('\\n')\n",
    "    body = text[1]\n",
    "    sender = header[2].split(':')[1].split('<')[0]\n",
    "#     print('Sender',sender)\n",
    "#     print('Body \\n',body)\n",
    "    return sender,body\n",
    "\n",
    "def clean_debian(temp):\n",
    "    temp = re.sub('\\n+','\\n',temp)\n",
    "    temp = re.sub('\\n',' ',temp)\n",
    "    temp = re.sub('\\t',' ',temp)\n",
    "    temp = re.sub(' +',' ',temp)\n",
    "    return temp\n",
    "\n",
    "def deb_lemmatize(doc):        \n",
    "    doc = nlp(doc)\n",
    "    article, skl_texts = '',''\n",
    "    for w in doc:\n",
    "        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            article += \" \" + w.lemma_\n",
    "        if w.text == '\\n':                \n",
    "            skl_texts += \" \" + article\n",
    "            article = ''       \n",
    "    return skl_texts\n",
    "\n",
    "def deb_toppostremoval(temp):\n",
    "    strings = temp.splitlines()\n",
    "    temp = ''\n",
    "    for st in strings:\n",
    "        st = st.strip()\n",
    "        if len(st)>0:\n",
    "            if st[0]=='>':\n",
    "                continue\n",
    "            else:\n",
    "                temp += '\\n' + st\n",
    "    return temp\n",
    "\n",
    "df = pd.DataFrame()\n",
    "folder = glob.glob(folder_path)\n",
    "obj = preprocessing.preprocess()\n",
    "count_file = 0\n",
    "thread_list=[]\n",
    "try:\n",
    "    for fol in tqdm_notebook(folder):\n",
    "        files = glob.glob(fol+'/*.txt')\n",
    "        threads = []\n",
    "        for file in files:\n",
    "            ob = read_file.file_content(file)\n",
    "            ob.read_file_content()\n",
    "            threads.append(ob.mail)\n",
    "            count_file += 1\n",
    "        sorted_threads = sorted(threads, key=lambda ke: datetime.datetime.strptime(ke['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "        thread_list.append(sorted_threads)\n",
    "except:\n",
    "    print(fol)\n",
    "print(len(thread_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"/home/anuja/Desktop/BE project/Models/InferSent/infersent1.pkl\"\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "infermodel = InferSent(params_model)\n",
    "infermodel.load_state_dict(torch.load(MODEL_PATH))\n",
    "use_cuda = False\n",
    "infermodel = infermodel.cuda() if use_cuda else infermodel\n",
    "W2V_PATH = '/home/anuja/Desktop/BE project/glove.6B/glove.840B.300d.txt'\n",
    "#replace with glove.840B.300d.txt\n",
    "infermodel.set_w2v_path(W2V_PATH)\n",
    "infermodel.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 2087/2087 (100.0%)\n",
      "Speed : 20.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03650786 -0.04985265 -0.02311382 ... -0.02699613 -0.02101633\n",
      "  0.00768024]\n",
      "Nb words kept : 61/61 (100.0%)\n",
      "Speed : 22.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0358405  -0.0489863  -0.02340721 ... -0.03197146 -0.0195006\n",
      "  0.00036863]\n",
      "Nb words kept : 1274/1274 (100.0%)\n",
      "Speed : 23.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03571672 -0.04736275 -0.02346319 ... -0.02552481 -0.02052212\n",
      "  0.00722022]\n",
      "Nb words kept : 426/426 (100.0%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03380246 -0.04779268 -0.02394018 ... -0.02711713 -0.02011451\n",
      "  0.00934879]\n",
      "Nb words kept : 185/185 (100.0%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03249109 -0.04508093 -0.02424568 ... -0.03202257 -0.01960267\n",
      "  0.00985559]\n",
      "Nb words kept : 1060/1060 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03561683 -0.04890719 -0.02283118 ... -0.02679757 -0.02073223\n",
      "  0.00711691]\n",
      "Nb words kept : 926/926 (100.0%)\n",
      "Speed : 19.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03301834 -0.0504004  -0.02307475 ... -0.02671313 -0.02015229\n",
      "  0.00764935]\n",
      "Nb words kept : 86/86 (100.0%)\n",
      "Speed : 23.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03127065 -0.0548249  -0.02436496 ... -0.03346186 -0.02044641\n",
      "  0.00369371]\n",
      "Nb words kept : 1158/1158 (100.0%)\n",
      "Speed : 20.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03510609 -0.04768544 -0.02278143 ... -0.0241038  -0.02033519\n",
      "  0.00853975]\n",
      "Nb words kept : 943/943 (100.0%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03281816 -0.04747972 -0.02288572 ... -0.02539052 -0.02069918\n",
      "  0.00760722]\n",
      "Nb words kept : 611/644 (94.9%)\n",
      "Speed : 20.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0324127  -0.04951782 -0.02423733 ... -0.02643531 -0.02114045\n",
      "  0.00508294]\n",
      "Nb words kept : 982/982 (100.0%)\n",
      "Speed : 21.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03609572 -0.04953315 -0.02273726 ... -0.02615092 -0.02090792\n",
      "  0.00861685]\n",
      "Nb words kept : 1667/1667 (100.0%)\n",
      "Speed : 22.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0336316  -0.04814012 -0.02308935 ... -0.02550804 -0.02040648\n",
      "  0.00718124]\n",
      "Nb words kept : 1070/1070 (100.0%)\n",
      "Speed : 23.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03509703 -0.05019497 -0.02377053 ... -0.02644871 -0.01996711\n",
      "  0.00530108]\n",
      "Nb words kept : 332/332 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03695963 -0.04954229 -0.02232689 ... -0.02706107 -0.02106253\n",
      "  0.00785352]\n",
      "Nb words kept : 1154/1154 (100.0%)\n",
      "Speed : 23.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03522208 -0.05382589 -0.0234854  ... -0.02857328 -0.02015925\n",
      "  0.0061062 ]\n",
      "Nb words kept : 631/631 (100.0%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03452682 -0.04982984 -0.02575443 ... -0.02760165 -0.02004567\n",
      "  0.00919815]\n",
      "Nb words kept : 511/511 (100.0%)\n",
      "Speed : 23.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03519882 -0.04719408 -0.02372056 ... -0.02784616 -0.0203593\n",
      "  0.00857114]\n",
      "Nb words kept : 655/655 (100.0%)\n",
      "Speed : 21.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03532493 -0.0485727  -0.02221289 ... -0.02366069 -0.02055858\n",
      "  0.0073095 ]\n",
      "Nb words kept : 1338/1338 (100.0%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03365271 -0.05059578 -0.02339599 ... -0.02680531 -0.02020983\n",
      "  0.00876525]\n",
      "Nb words kept : 191/196 (97.4%)\n",
      "Speed : 24.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03756586 -0.04951707 -0.02517573 ... -0.02928659 -0.02028158\n",
      "  0.00365933]\n",
      "Nb words kept : 125/125 (100.0%)\n",
      "Speed : 22.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03356638 -0.04988033 -0.02425322 ... -0.03236214 -0.01822769\n",
      "  0.00763387]\n",
      "Nb words kept : 192/192 (100.0%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03438283 -0.04692958 -0.02611575 ... -0.03288321 -0.02009813\n",
      "  0.01445763]\n",
      "Nb words kept : 1384/1384 (100.0%)\n",
      "Speed : 22.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03377588 -0.04997748 -0.0235955  ... -0.02631869 -0.02045715\n",
      "  0.00862632]\n",
      "Nb words kept : 644/644 (100.0%)\n",
      "Speed : 23.4 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03479477 -0.04337113 -0.02386298 ... -0.02748765 -0.01980403\n",
      "  0.01333025]\n",
      "Nb words kept : 730/730 (100.0%)\n",
      "Speed : 20.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03415361 -0.04927798 -0.02463673 ... -0.0278078  -0.02044559\n",
      "  0.00878555]\n",
      "Nb words kept : 573/573 (100.0%)\n",
      "Speed : 22.4 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03261728 -0.04704344 -0.02392856 ... -0.02723016 -0.01990513\n",
      "  0.00811272]\n",
      "Nb words kept : 1630/1630 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03520057 -0.04808192 -0.02349778 ... -0.02674324 -0.0205839\n",
      "  0.00911206]\n",
      "Nb words kept : 3543/3543 (100.0%)\n",
      "Speed : 22.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03634774 -0.04799621 -0.02294348 ... -0.02587381 -0.02069629\n",
      "  0.00936187]\n",
      "Nb words kept : 583/583 (100.0%)\n",
      "Speed : 22.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03526119 -0.04393779 -0.02305213 ... -0.0285142  -0.01971995\n",
      "  0.0102256 ]\n",
      "Nb words kept : 347/347 (100.0%)\n",
      "Speed : 23.7 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03324527 -0.04220981 -0.02351634 ... -0.02642816 -0.01983942\n",
      "  0.01351205]\n",
      "Nb words kept : 3147/3147 (100.0%)\n",
      "Speed : 22.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03427351 -0.04858157 -0.02313639 ... -0.02676782 -0.02024087\n",
      "  0.00674766]\n",
      "Nb words kept : 464/464 (100.0%)\n",
      "Speed : 21.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0334283  -0.04972581 -0.02259342 ... -0.02578549 -0.02023853\n",
      "  0.00807584]\n",
      "Nb words kept : 657/657 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03179156 -0.04627158 -0.02399601 ... -0.02646301 -0.01925585\n",
      "  0.01045209]\n",
      "Nb words kept : 1378/1378 (100.0%)\n",
      "Speed : 23.7 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03408506 -0.04964183 -0.02423879 ... -0.02589438 -0.02071451\n",
      "  0.00629503]\n",
      "Nb words kept : 143/143 (100.0%)\n",
      "Speed : 22.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03268387 -0.04703028 -0.02647162 ... -0.02845889 -0.01942962\n",
      "  0.01181948]\n",
      "Nb words kept : 328/328 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03723575 -0.04952787 -0.02371998 ... -0.02696165 -0.02053273\n",
      "  0.0063724 ]\n",
      "Nb words kept : 742/742 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03714425 -0.05178056 -0.02368604 ... -0.02666738 -0.02092729\n",
      "  0.0053703 ]\n",
      "Nb words kept : 1137/1137 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03419991 -0.0478261  -0.02343686 ... -0.02696468 -0.02042063\n",
      "  0.0082419 ]\n",
      "Nb words kept : 745/745 (100.0%)\n",
      "Speed : 23.7 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03420499 -0.04997543 -0.02328048 ... -0.02815232 -0.02040299\n",
      "  0.00753364]\n",
      "Nb words kept : 965/965 (100.0%)\n",
      "Speed : 23.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03245414 -0.04770159 -0.02298835 ... -0.02714876 -0.01995586\n",
      "  0.00781341]\n",
      "Nb words kept : 3191/3191 (100.0%)\n",
      "Speed : 22.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03398129 -0.05072618 -0.02367246 ... -0.02667503 -0.02049353\n",
      "  0.00742099]\n",
      "Nb words kept : 354/354 (100.0%)\n",
      "Speed : 22.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03298683 -0.04692332 -0.0247501  ... -0.02613176 -0.02060174\n",
      "  0.01122376]\n",
      "Nb words kept : 371/371 (100.0%)\n",
      "Speed : 23.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03302832 -0.04640603 -0.02449457 ... -0.02579163 -0.02049156\n",
      "  0.0116393 ]\n",
      "Nb words kept : 383/383 (100.0%)\n",
      "Speed : 23.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03293944 -0.0480025  -0.02359665 ... -0.0257715  -0.02058099\n",
      "  0.00897267]\n",
      "Nb words kept : 378/378 (100.0%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03218424 -0.04757933 -0.02391706 ... -0.02584687 -0.02091722\n",
      "  0.00901766]\n",
      "Nb words kept : 616/616 (100.0%)\n",
      "Speed : 24.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0361522  -0.04890728 -0.02311746 ... -0.02618201 -0.02150143\n",
      "  0.00744894]\n",
      "Nb words kept : 728/728 (100.0%)\n",
      "Speed : 22.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03363013 -0.04785987 -0.02297884 ... -0.02630967 -0.02097708\n",
      "  0.00643261]\n",
      "Nb words kept : 1258/1258 (100.0%)\n",
      "Speed : 21.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03415596 -0.04650421 -0.02318701 ... -0.02822301 -0.01995231\n",
      "  0.01103573]\n",
      "Nb words kept : 915/915 (100.0%)\n",
      "Speed : 21.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03543242 -0.04877467 -0.02316972 ... -0.02624449 -0.02110215\n",
      "  0.007179  ]\n",
      "Nb words kept : 549/549 (100.0%)\n",
      "Speed : 20.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03495893 -0.05288158 -0.02417889 ... -0.02745664 -0.0207377\n",
      "  0.00652269]\n",
      "Nb words kept : 1725/1725 (100.0%)\n",
      "Speed : 20.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03339916 -0.04955882 -0.02236236 ... -0.02622046 -0.02071945\n",
      "  0.00610312]\n",
      "Nb words kept : 963/963 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 20.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03568519 -0.04481908 -0.02233277 ... -0.02482249 -0.02047235\n",
      "  0.00748657]\n",
      "Nb words kept : 342/342 (100.0%)\n",
      "Speed : 20.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0319744  -0.04911947 -0.0237011  ... -0.02877466 -0.02015302\n",
      "  0.00337766]\n",
      "Nb words kept : 206/206 (100.0%)\n",
      "Speed : 20.8 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03349618 -0.04706893 -0.02318899 ... -0.02599528 -0.02113654\n",
      "  0.01188441]\n",
      "Nb words kept : 171/171 (100.0%)\n",
      "Speed : 21.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03582375 -0.05241599 -0.02550579 ... -0.03193107 -0.02023388\n",
      "  0.00749555]\n",
      "Nb words kept : 135/135 (100.0%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03446902 -0.05008711 -0.02461352 ... -0.0275008  -0.02051609\n",
      "  0.01554701]\n",
      "Nb words kept : 680/680 (100.0%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03550123 -0.05193973 -0.02371666 ... -0.02561482 -0.02042306\n",
      "  0.00408496]\n",
      "Nb words kept : 1117/1117 (100.0%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03408157 -0.050688   -0.02223091 ... -0.02534392 -0.02067577\n",
      "  0.0053997 ]\n",
      "Nb words kept : 541/542 (99.8%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03580596 -0.04949609 -0.02319704 ... -0.02646609 -0.02054307\n",
      "  0.00574208]\n",
      "Nb words kept : 252/252 (100.0%)\n",
      "Speed : 21.0 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03859271 -0.05052555 -0.02398468 ... -0.02779067 -0.02067274\n",
      "  0.00734398]\n",
      "Nb words kept : 591/591 (100.0%)\n",
      "Speed : 21.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03717109 -0.04639256 -0.0238454  ... -0.02646556 -0.02045178\n",
      "  0.00781497]\n",
      "Nb words kept : 242/242 (100.0%)\n",
      "Speed : 23.3 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.0358721  -0.04313317 -0.0226201  ... -0.02686038 -0.02118893\n",
      "  0.01224343]\n",
      "Nb words kept : 365/365 (100.0%)\n",
      "Speed : 23.7 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03355702 -0.04461409 -0.02370112 ... -0.02820519 -0.0200332\n",
      "  0.01097105]\n",
      "Nb words kept : 553/553 (100.0%)\n",
      "Speed : 20.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03274444 -0.04623545 -0.0219819  ... -0.02420941 -0.02019176\n",
      "  0.00704833]\n",
      "Nb words kept : 355/358 (99.2%)\n",
      "Speed : 22.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03044696 -0.04696618 -0.02585173 ... -0.02676334 -0.02063863\n",
      "  0.00393798]\n",
      "Nb words kept : 268/268 (100.0%)\n",
      "Speed : 21.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.02857665 -0.0409672  -0.02317752 ... -0.02446624 -0.01934366\n",
      "  0.00777286]\n",
      "Nb words kept : 1263/1263 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03221226 -0.04722181 -0.02389717 ... -0.02542316 -0.02007682\n",
      "  0.00682364]\n",
      "Nb words kept : 183/183 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03626772 -0.04941119 -0.02072252 ... -0.02924612 -0.02101059\n",
      "  0.00468004]\n",
      "Nb words kept : 229/229 (100.0%)\n",
      "Speed : 24.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03465601 -0.04988361 -0.02545393 ... -0.02840844 -0.02016129\n",
      "  0.01082141]\n",
      "Nb words kept : 149/149 (100.0%)\n",
      "Speed : 24.4 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03049531 -0.04710522 -0.02394022 ... -0.02382558 -0.02012284\n",
      "  0.0078475 ]\n",
      "Nb words kept : 195/195 (100.0%)\n",
      "Speed : 24.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03349913 -0.04621373 -0.02439458 ... -0.02967224 -0.019996\n",
      "  0.01001824]\n",
      "Nb words kept : 866/866 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03379027 -0.05182993 -0.02398854 ... -0.02701375 -0.02054246\n",
      "  0.00682167]\n",
      "Nb words kept : 572/573 (99.8%)\n",
      "Speed : 24.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03337945 -0.04778165 -0.02452965 ... -0.02698427 -0.01947127\n",
      "  0.00791762]\n",
      "Nb words kept : 608/609 (99.8%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03486131 -0.0466071  -0.023663   ... -0.02557546 -0.02047107\n",
      "  0.00858088]\n",
      "Nb words kept : 557/557 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03263823 -0.04634768 -0.02235447 ... -0.02566579 -0.0203281\n",
      "  0.00714985]\n",
      "Nb words kept : 396/396 (100.0%)\n",
      "Speed : 22.7 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03470849 -0.04962419 -0.02325918 ... -0.02820229 -0.02028\n",
      "  0.00553446]\n",
      "Nb words kept : 385/385 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03371356 -0.04937713 -0.02379557 ... -0.02826441 -0.01933338\n",
      "  0.00760067]\n",
      "Nb words kept : 352/352 (100.0%)\n",
      "Speed : 23.4 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03324122 -0.04626084 -0.02315455 ... -0.02479808 -0.02043119\n",
      "  0.0086546 ]\n",
      "Nb words kept : 3029/3033 (99.9%)\n",
      "Speed : 22.2 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03403204 -0.04690861 -0.02282357 ... -0.02569436 -0.02042624\n",
      "  0.00698755]\n",
      "Nb words kept : 368/368 (100.0%)\n",
      "Speed : 23.5 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03269885 -0.04818986 -0.02467461 ... -0.0261472  -0.0197955\n",
      "  0.00838143]\n",
      "Nb words kept : 167/167 (100.0%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03444761 -0.0489645  -0.02305779 ... -0.02740398 -0.02040335\n",
      "  0.0081621 ]\n",
      "Nb words kept : 408/408 (100.0%)\n",
      "Speed : 23.6 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03733141 -0.04632816 -0.02244332 ... -0.02814176 -0.02114352\n",
      "  0.00834144]\n",
      "Nb words kept : 736/739 (99.6%)\n",
      "Speed : 23.9 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03480833 -0.0495456  -0.02408373 ... -0.03066386 -0.0200518\n",
      "  0.00766012]\n",
      "Nb words kept : 267/267 (100.0%)\n",
      "Speed : 23.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03234564 -0.0500076  -0.02533817 ... -0.03142785 -0.02056858\n",
      "  0.00896022]\n",
      "Nb words kept : 220/220 (100.0%)\n",
      "Speed : 21.1 sentences/s (cpu mode, bsize=1)\n",
      "[ 0.03272925 -0.05023838 -0.02285942 ... -0.02848677 -0.01998239\n",
      "  0.00345555]\n",
      "6\n",
      "92\n",
      "63\n",
      "23\n",
      "37\n",
      "4096\n",
      "{'': 31,\n",
      " '\"Adam D. Barratt\"': 29,\n",
      " 'Adam Borowski': 50,\n",
      " 'Adrian Bunk': 2,\n",
      " 'Afif Elghraoui': 7,\n",
      " 'Alexander Wirt': 15,\n",
      " 'Andreas Tille': 10,\n",
      " 'Ansgar Burchardt': 48,\n",
      " 'Anton Gladky': 39,\n",
      " 'Attila Szalay': 12,\n",
      " 'Bastien ROUCARIES': 22,\n",
      " 'Ben Hutchings': 26,\n",
      " 'Carsten Schoenert': 11,\n",
      " 'Chris Lamb': 1,\n",
      " 'Christian Seiler': 23,\n",
      " 'Colin Ian King': 30,\n",
      " 'Dmitry Bogatov': 52,\n",
      " 'Evgeni Golov': 40,\n",
      " 'Fabian Greffrath': 49,\n",
      " 'Florian Lohoff': 19,\n",
      " 'Geert Stappers': 16,\n",
      " 'Ghislain Vaillant': 5,\n",
      " 'Hans': 24,\n",
      " 'Henrique de Moraes Holschuh': 32,\n",
      " 'Hilko Bengen': 28,\n",
      " 'Holger Levsen': 45,\n",
      " 'Ian Jackson': 25,\n",
      " 'Jeremy Bicha': 42,\n",
      " 'Joerg Jaspert': 13,\n",
      " 'Jonas Smedegaard': 6,\n",
      " 'Jonathan Dowland': 41,\n",
      " 'Julian Andres Klode': 27,\n",
      " 'Marc Haber': 9,\n",
      " 'Marvin Renich': 37,\n",
      " 'Michael Lustfield': 46,\n",
      " 'Michael Stapelberg': 47,\n",
      " 'Nikolaus Rath': 21,\n",
      " 'Ole Streicher': 43,\n",
      " 'Paul Gevers': 8,\n",
      " 'Paul Wise': 18,\n",
      " 'Pavlo Solntsev': 17,\n",
      " 'Philipp Hahn': 34,\n",
      " 'Philipp Kern': 4,\n",
      " 'Pirate Praveen': 3,\n",
      " 'Russ Allbery': 33,\n",
      " 'Steve McIntyre': 35,\n",
      " 'Stuart Prescott': 51,\n",
      " 'Thibaut Paumard': 44,\n",
      " 'Vincent Bernat': 38,\n",
      " 'Wouter Verhelst': 20,\n",
      " 'jvieira33@sapo.pt': 36,\n",
      " 'shirish शिरीष': 14}\n"
     ]
    }
   ],
   "source": [
    "df_trn = pd.DataFrame()\n",
    "df_tst = pd.DataFrame()\n",
    "split_date = datetime.datetime.strptime('01 Sep 2017 23:01:14 +0000', '%d %b %Y %H:%M:%S %z')\n",
    "\n",
    "users = []\n",
    "trn_users = []\n",
    "tst_users = []\n",
    "th_no = 0\n",
    "cnt = 0\n",
    "for thr in thread_list:\n",
    "    start_date = \"\"\n",
    "    flag = 0\n",
    "    t = ''\n",
    "    for mail in thr:\n",
    "        temp = ''\n",
    "        sender = mail['From'].split('<')[0].strip()\n",
    "        temp   = mail['content']\n",
    "        users.append(sender)\n",
    "        temp = deb_toppostremoval(temp)\n",
    "        temp = deb_lemmatize(temp)\n",
    "        temp = clean_debian(temp)\n",
    "        if temp == '':\n",
    "            cnt += 1\n",
    "            continue\n",
    "        temp = obj.replace_tokens(temp)\n",
    "        if temp!='' :\n",
    "            embedding =infermodel.encode( str(temp), bsize=1, tokenize=False, verbose=True)\n",
    "            sent_vec =[]\n",
    "            numw = 0\n",
    "            for w in embedding:\n",
    "                try:\n",
    "                    if numw == 0:\n",
    "                        sent_vec = w\n",
    "                    else:\n",
    "                        sent_vec = np.add(sent_vec, w)\n",
    "                    numw+=1\n",
    "                except:\n",
    "                    pass\n",
    "            v = np.asarray(sent_vec) / numw\n",
    "#             print(v.shape)\n",
    "#             print(v)\n",
    "            v=np.transpose(v)\n",
    "#             print(v.shape)\n",
    "            print(v)\n",
    "        if flag==0:\n",
    "            start_date = datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z')\n",
    "            if start_date > split_date:\n",
    "                df_tst = df_tst.append({'body': str(temp),'replier':sender, 'thread_no':th_no, 'start_date':start_date,'embeddings':v}, ignore_index=True)\n",
    "                tst_users.append(sender)\n",
    "            else:\n",
    "                trn_users.append(sender)\n",
    "            t = temp\n",
    "            flag = 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        df = df.append({'body': str(t),'replier':sender, 'thread_no':th_no, 'start_date':start_date,'embeddings':v}, ignore_index=True)\n",
    "\n",
    "        if start_date <= split_date:\n",
    "            df_trn = df_trn.append({'body': str(t),'replier':sender, 'thread_no':th_no, 'start_date':start_date,'embeddings':v}, ignore_index=True)\n",
    "            trn_users.append(sender)\n",
    "            t = t + temp\n",
    "        else:\n",
    "            df_tst = df_tst.append({'body': str(temp),'replier':sender, 'thread_no':th_no, 'start_date':start_date,'embeddings':v}, ignore_index=True)\n",
    "            tst_users.append(sender)\n",
    "\n",
    "        \n",
    "        #t = t + temp\n",
    "    th_no += 1\n",
    "\n",
    "print(cnt)\n",
    "print(count_file)\n",
    "print(len(df['body']))\n",
    "print(len(df['thread_no'].unique()))\n",
    "print(len(df['replier'].unique()))\n",
    "print(len(df['embeddings'][0]))\n",
    "rep_to_index = {}\n",
    "index = 0\n",
    "for rep in users:\n",
    "    if rep_to_index.get(rep, 0) == 0:\n",
    "        rep_to_index[rep] = index\n",
    "        index += 1\n",
    "pprint(rep_to_index)\n",
    "\n",
    "\n",
    "for rep in df_trn['replier']:\n",
    "    df_trn.loc[df_trn['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "#print(df_trn.head)    \n",
    "\n",
    "for rep in df_tst['replier']:\n",
    "    df_tst.loc[df_tst['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "\n",
    "for rep in df['replier']:\n",
    "    df.loc[df['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "    \n",
    "for rep in df['replier']:\n",
    "    df.loc[df['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "    \n",
    "\n",
    "#Offset the replier in test dataframe\n",
    "\n",
    "df_tst['replier'] = df_tst.groupby('thread_no')['replier'].shift(-1)\n",
    "df_tst['int_replier'] = df_tst.groupby('thread_no')['int_replier'].shift(-1)\n",
    "\n",
    "df_tst.dropna(inplace=True)\n",
    "\n",
    "df_trn.to_csv(file_name)\n",
    "df_tst.to_csv(file_name1)\n",
    "df.to_csv(file_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing of words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "for sent in df_trn.body.values:\n",
    "    words.update(w.text.lower() for w in nlp(sent))\n",
    "# print(words)\n",
    "\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "print(words)\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "def indexer(s):\n",
    "    vec = []\n",
    "    for wr in nlp(s):\n",
    "        wr = wr.text.lower()\n",
    "        if wr in word2idx:\n",
    "            vec.append(word2idx[wr])\n",
    "        else:\n",
    "            vec.append(word2idx['_PAD'])\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Vector - construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0dd594524dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtst_user_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0muser_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold = sys.maxsize)\n",
    "user_indices = []\n",
    "trn_user_indices = []\n",
    "tst_user_indices = []\n",
    "\n",
    "for u in users:\n",
    "    user_indices.append(rep_to_index[u])\n",
    "\n",
    "for v in trn_users:\n",
    "    trn_user_indices.append(rep_to_index[v])\n",
    "\n",
    "for w in tst_users:\n",
    "    tst_user_indices.append(rep_to_index[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bca82e07e9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_vec_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "user_vec_len = max(user_indices) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexx=0\n",
    "weight_list = []\n",
    "for i in range(0, df_trn.thread_no.shape[0]+1):\n",
    "    temp_index=indexx\n",
    "    array  = np.zeros(user_vec_len)\n",
    "    for j in range(temp_index, temp_index + list(df_trn.thread_no).count(i)):\n",
    "        array[trn_user_indices[j]] += 1\n",
    "        weight_list.append(list(array))\n",
    "        indexx+=1\n",
    "\n",
    "trn_weights = np.array(weight_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexx=0\n",
    "weight_list = []\n",
    "for i in range(0, df_tst.thread_no.shape[0]+1):\n",
    "    temp_index=indexx\n",
    "    array  = np.zeros(user_vec_len)\n",
    "    for j in range(temp_index, temp_index + list(df_tst.thread_no).count(i)):\n",
    "        array[tst_user_indices[j]] += 1\n",
    "        weight_list.append(list(array))\n",
    "        indexx+=1\n",
    "\n",
    "tst_weights = np.array(weight_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding |> flag\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path, maxlen=10, calc_maxlen = False):\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['body'] = self.df.body.apply(lambda x: x.strip())\n",
    "        print('Indexing...')\n",
    "        self.df['bodyidx'] = self.df.body.apply(indexer)\n",
    "        print('Calculating lengths')\n",
    "        self.df['lengths'] = self.df.bodyidx.apply(len)\n",
    "        if calc_maxlen == True:\n",
    "            self.maxlen = max(self.df['lengths'])\n",
    "        else:\n",
    "            self.maxlen = maxlen\n",
    "        print(self.maxlen)\n",
    "        print('Padding')\n",
    "        self.df['bodypadded'] = self.df.bodyidx.apply(self.pad_data)\n",
    "        print(self.df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.bodypadded[idx]\n",
    "        lens = self.df.lengths[idx]\n",
    "        y = self.df.int_replier[idx]\n",
    "        e=self.df.embeddings[idx]\n",
    "        return X,y,lens,e\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = VectorizeData(file_name2, calc_maxlen = True)\n",
    "dtrain = VectorizeData(file_name, maxlen = ds.maxlen)\n",
    "dtest = VectorizeData(file_name1, maxlen = ds.maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Feedforward Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ds.maxlen\n",
    "hidden_size = 50\n",
    "num_classes = user_vec_len\n",
    "num_epochs = 5\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings |>\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,user_vec_len, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + user_vec_len, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x,w):\n",
    "#         x = torch.FloatTensor(x) \n",
    "        catt = torch.cat((x,w),1)\n",
    "        out = self.fc1(catt)\n",
    "        out = self.relu(out)       \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size,user_vec_len, num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl= DataLoader(dtrain, batch_size=1)\n",
    "num_batch = len(train_dl)\n",
    "for epoch in range(num_epochs):\n",
    "    y_true_train = list()\n",
    "    y_pred_train = list()\n",
    "    total_loss_train = 0\n",
    "    t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "    for we, w in zip(t,trn_weights):\n",
    "        X = we[0]\n",
    "        y = we[1]\n",
    "        lengths = we[2]\n",
    "        \n",
    "        w = w.reshape(-1,1)\n",
    "        w = w.transpose()\n",
    "        \n",
    "        w = Variable(torch.Tensor(w).cpu())\n",
    "        X = Variable(X.cpu())\n",
    "        y = Variable(y.cpu())\n",
    "        lengths = lengths.numpy()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        X = X.float()\n",
    "        w = w.float()\n",
    "        y = y.long()\n",
    "        pred = model(X,w)\n",
    "        # F.nll_loss can be replaced with criterion\n",
    "        loss = F.nll_loss(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        t.set_postfix(loss=loss.item())\n",
    "        pred_idx = torch.max(pred, dim=1)[1]\n",
    "\n",
    "        y_true_train += list(y.cpu().data.numpy())\n",
    "        y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "        total_loss_train += loss.item()\n",
    "        \n",
    "\n",
    "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_loss = total_loss_train/len(train_dl)\n",
    "    print(f' Epoch {epoch}: Train loss: {train_loss} acc: {train_acc}')\n",
    "torch.save(model.state_dict(),PATH)\n",
    "\n",
    "# architecture \n",
    "# loading pickle file and predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl= DataLoader(dtest, batch_size=1)\n",
    "num_batches = len(test_dl)\n",
    "y_true_test1 = list()\n",
    "y_pred_test1 = list()\n",
    "total_loss_train = 0\n",
    "tt = tqdm_notebook(iter(test_dl), leave=False, total=num_batch)\n",
    "for we, w in zip(tt,tst_weights):\n",
    "    X = we[0]\n",
    "    y = we[1]\n",
    "    lengths = we[2]\n",
    "    \n",
    "    w = w.reshape(-1,1)\n",
    "    w = w.transpose()\n",
    "\n",
    "    w = Variable(torch.Tensor(w).cpu())\n",
    "    X = Variable(X.cpu())\n",
    "    y = Variable(y.cpu())\n",
    "    lengths = lengths.numpy()\n",
    "\n",
    "    X = X.float()\n",
    "    w = w.float()\n",
    "    y = y.long()\n",
    "    pred = model(X,w)\n",
    "    loss = F.nll_loss(pred, y)\n",
    "\n",
    "\n",
    "    y_true_train += list(y.cpu().data.numpy())\n",
    "    y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "    total_loss_train += loss.item()\n",
    "\n",
    "train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "train_loss = total_loss_train/len(train_dl)\n",
    "print(f' Epoch {epoch}: Train loss: {train_loss} acc: {train_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
